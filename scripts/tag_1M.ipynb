{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training 1M images using Inception retrained on our validated 10K images\n",
    "\n",
    "\n",
    "This code is adapted from tensorflow/tensorflow/models/image/imagenet/classify_image.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os.path\n",
    "import re\n",
    "import sys\n",
    "import tarfile\n",
    "import time\n",
    "import multiprocessing as mp\n",
    "import itertools\n",
    "\n",
    "import tensorflow.python.platform\n",
    "from six.moves import urllib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import h5py\n",
    "import glob\n",
    "import cPickle as pickle\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tensorflow.python.platform import gfile\n",
    "\n",
    "from run_inference import predict_star, predict\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to read in a graph + optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_graph(pb_file):\n",
    "    \"\"\"\"Creates a graph from saved GraphDef file and returns a Graph object.\n",
    "    Returns:\n",
    "    Graph holding the trained Inception network.\n",
    "    \"\"\"\n",
    "    model_filename = pb_file\n",
    "    with gfile.FastGFile(model_filename, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        tf.import_graph_def(graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#graph = create_graph\"/data/retrain_manualtags/output_graph_best.pb\")\n",
    "create_graph(\"/data/output_graphfinal.pb\")\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12,)\n",
      "(2048, 12)\n"
     ]
    }
   ],
   "source": [
    "params = pickle.load(open(\"/data/10k_aug_outputs/output_params_lr1e-3_adam9800.pkl\", 'r'))\n",
    "fw = params[\"final_weights\"]\n",
    "fb = params[\"final_biases\"]\n",
    "print fb.shape\n",
    "print fw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['animals',\n",
       " 'nature',\n",
       " 'text',\n",
       " 'maps',\n",
       " 'people',\n",
       " 'seals',\n",
       " 'miniatures',\n",
       " 'objects',\n",
       " 'architecture',\n",
       " 'decorations',\n",
       " 'landscapes',\n",
       " 'diagrams']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "with open(\"/data/10k_aug_outputs/output_labels9800.txt\", 'r') as ifile:\n",
    "    for line in ifile:\n",
    "        labels.append(line.rstrip())\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code to calculate scores on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from http://www.socouldanyone.com/2013/03/converting-grayscale-to-rgb-with-numpy.html\n",
    "def to_rgb(im):\n",
    "    w, h = im.shape[:2]\n",
    "    ret = np.empty((w, h, 3), dtype=np.uint8)\n",
    "    ret[:, :, 0] = im\n",
    "    ret[:, :, 1] = im\n",
    "    ret[:, :, 2] = im\n",
    "    return ret\n",
    "\n",
    "# from http://www.socouldanyone.com/2013/03/converting-grayscale-to-rgb-with-numpy.html\n",
    "def to_rgbs(im):\n",
    "    n, w, h = im.shape[:3]\n",
    "    ret = np.empty((n, w, h, 3), dtype=np.uint8)\n",
    "    ret[:, :, :, 0] = im[:,:,:,0]\n",
    "    ret[:, :, :, 1] = im[:,:,:,0]\n",
    "    ret[:, :, :, 2] = im[:,:,:,0]\n",
    "    return ret\n",
    "\n",
    "# from https://gist.github.com/yusugomori/4462221\n",
    "def softmax(x):\n",
    "    e = np.exp(x - np.max(x))  # prevent overflow\n",
    "    if e.ndim == 1:\n",
    "        return e / np.sum(e, axis=0)\n",
    "    else:  \n",
    "        return e / np.array([np.sum(e, axis=1)]).T  # ndim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_inference_on_image(image, fileType, visualize=True, verbose=True):\n",
    "    # Some useful tensors:\n",
    "    # 'softmax:0': A tensor containing the normalized prediction across\n",
    "    #   1000 labels.\n",
    "    # 'pool_3:0': A tensor containing the next-to-last layer containing 2048\n",
    "    #   float description of the image.\n",
    "    # 'DecodeJpeg/contents:0': A tensor containing a string providing JPEG\n",
    "    #   encoding of the image.\n",
    "    # Runs the softmax tensor by feeding the image_data as input to the graph.\n",
    "\n",
    "    softmax_tensor = sess.graph.get_tensor_by_name('pool_3/_reshape:0')\n",
    "    \n",
    "    if fileType=='jpg':\n",
    "        if not gfile.Exists(image):\n",
    "            tf.logging.fatal('File does not exist %s', image)\n",
    "        image_data = gfile.FastGFile(image).read()\n",
    "        predictions = sess.run(softmax_tensor, {'DecodeJpeg/contents:0': image_data})\n",
    "    elif fileType=='arr':\n",
    "        image_data = [to_rgb(image)]\n",
    "        predictions = sess.run(softmax_tensor, {'ExpandDims:0': image_data})\n",
    "    else:\n",
    "        print \"Must be jpg or arr.\"\n",
    "        return\n",
    "\n",
    "    preds = softmax((np.dot(predictions, fw) + fb)[0])\n",
    "    top_k = preds.argsort()[-12:][::-1]\n",
    "    \n",
    "    for node_id in top_k:\n",
    "      score = preds[node_id]\n",
    "      if verbose:\n",
    "            print '%s (score = %.5f)' % (labels[int(node_id)], score)\n",
    "       \n",
    "    if visualize:\n",
    "        if fileType=='jpg': plt.imshow(mpimg.imread(image), cmap=mpl.cm.gray)\n",
    "        else:\n",
    "            plt.imshow(image, cmap=mpl.cm.gray)\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = mpimg.imread(\"/data/reorg3/Maps/003055002_10_000599_1_.jpg\")\n",
    "print x.shape\n",
    "preds = run_inference_on_image(x, fileType=\"arr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in 10K images from our hdf5 file, and score their scores in a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in hdf5 file\n",
    "image_hdf5 = h5py.File('/data/image_data.hdf5','r')\n",
    "(image_metadata, book_metadata, image_to_idx) = pickle.load(open(\"/data/all_metadata_w11ktags.pkl\", 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_to_idx.keys()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tagged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d367e116b564>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnum_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mimages_for_tagging\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_to_idx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtagged\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mimages_for_tagging\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tagged' is not defined"
     ]
    }
   ],
   "source": [
    "# choose 10k pictures not in the tagged set\n",
    "\n",
    "num_images = 10000\n",
    "images_for_tagging = list(np.random.choice(list(set(image_to_idx.keys()) - tagged), size=10000, replace=False))\n",
    "images_for_tagging[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.338056087494\n"
     ]
    }
   ],
   "source": [
    "images_to_scores = {}\n",
    "args = {\"images_to_scores\": images_to_scores, \n",
    "        \"image_to_idx\": image_to_idx, \n",
    "        \"image_hdf5\": image_hdf5, \n",
    "        \"fw\": fw, \n",
    "        \"fb\": fb, \n",
    "        \"sess\": sess}\n",
    "\n",
    "s = time.time()\n",
    "\n",
    "for img in image_to_idx:\n",
    "    try:\n",
    "        predict_star((img, args))\n",
    "    except:\n",
    "        continue\n",
    "    break\n",
    "f = time.time()\n",
    "print f - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = image_hdf5[\"Chunk0\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 224, 224, 3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = to_rgbs(a)\n",
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.00107693672\n"
     ]
    }
   ],
   "source": [
    "softmax_tensor = sess.graph.get_tensor_by_name('pool_3:0')\n",
    "s = time.time()\n",
    "a = to_rgbs(image_hdf5[\"Chunk0\"][:10])\n",
    "predictions = sess.run(softmax_tensor, {'ExpandDims:0': a})[:,0,0,:]\n",
    "preds = np.dot(predictions, fw) + fb\n",
    "preds = np.array([softmax(preds[i]) for i in range(preds.shape[0])])\n",
    "#top_k = preds.argsort()[-12:][::-1]\n",
    "f = time.time()\n",
    "print f - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.75737689e-04,   1.02026061e-04,   4.98217717e-03,\n",
       "          4.85685587e-06,   1.02797442e-03,   5.87578535e-01,\n",
       "          4.00601804e-01,   2.42072949e-03,   1.07868400e-03,\n",
       "          1.38594361e-03,   5.95708960e-04,   4.58377472e-05],\n",
       "       [  2.15077616e-05,   2.75007933e-05,   1.85669761e-03,\n",
       "          8.34639504e-05,   3.02390486e-04,   1.90650150e-02,\n",
       "          6.75299644e-01,   2.04064627e-03,   1.37578609e-04,\n",
       "          3.00988913e-01,   9.23561765e-06,   1.67372084e-04],\n",
       "       [  9.74729119e-07,   4.92729923e-05,   5.06105553e-03,\n",
       "          1.29475484e-05,   3.84568266e-05,   4.57915328e-02,\n",
       "          6.69574857e-01,   1.89486111e-03,   1.01982346e-06,\n",
       "          2.77573735e-01,   9.18649789e-07,   3.11069527e-07],\n",
       "       [  1.62652746e-01,   1.79588422e-03,   6.08959794e-03,\n",
       "          5.86105213e-02,   3.63012403e-01,   2.35896647e-01,\n",
       "          8.16231687e-03,   6.69940189e-02,   1.16148004e-02,\n",
       "          8.14899504e-02,   3.26358154e-03,   4.17619915e-04],\n",
       "       [  1.52357807e-03,   8.55193648e-04,   4.42944607e-03,\n",
       "          7.52604892e-03,   2.62244861e-03,   7.23113120e-02,\n",
       "          9.00874257e-01,   4.02122969e-03,   1.47805578e-04,\n",
       "          4.95387055e-03,   3.09464143e-04,   4.25408740e-04],\n",
       "       [  6.00119308e-03,   6.09563373e-04,   1.64277051e-02,\n",
       "          9.65145649e-04,   3.63081018e-03,   8.26476589e-02,\n",
       "          8.69922757e-01,   5.89024881e-03,   2.82809720e-04,\n",
       "          1.28218867e-02,   3.45466018e-04,   4.54786932e-04],\n",
       "       [  3.60279949e-03,   2.14592932e-04,   5.86830139e-01,\n",
       "          2.82754452e-04,   8.80257040e-02,   1.83078628e-02,\n",
       "          8.03937297e-03,   1.28339678e-01,   1.51034132e-01,\n",
       "          1.10427067e-02,   4.16452577e-03,   1.15682975e-04],\n",
       "       [  1.80176215e-03,   1.65280630e-06,   1.90061866e-03,\n",
       "          2.97097131e-06,   9.83696878e-01,   7.02178431e-06,\n",
       "          1.66135180e-07,   1.25298798e-02,   3.92177426e-05,\n",
       "          1.39959707e-06,   1.81690593e-05,   1.92040247e-07],\n",
       "       [  3.60279949e-03,   2.14592932e-04,   5.86830139e-01,\n",
       "          2.82754452e-04,   8.80257040e-02,   1.83078628e-02,\n",
       "          8.03937297e-03,   1.28339678e-01,   1.51034132e-01,\n",
       "          1.10427067e-02,   4.16452577e-03,   1.15682975e-04],\n",
       "       [  1.80176215e-03,   1.65280630e-06,   1.90061866e-03,\n",
       "          2.97097131e-06,   9.83696878e-01,   7.02178431e-06,\n",
       "          1.66135180e-07,   1.25298798e-02,   3.92177426e-05,\n",
       "          1.39959707e-06,   1.81690593e-05,   1.92040247e-07]], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([softmax(preds[i]) for i in range(preds.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# let's export a image to tag mapping so we can start validating\n",
    "image_to_tags = {}\n",
    "for img in images_to_scores:\n",
    "    image_to_tags[img] = labels[np.argmax(images_to_scores[img])]\n",
    "pickle.dump(image_to_tags, open(\"image_to_tags_10k.pkl\", 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra code (to try to parallelize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lolol i tried to parallelize\n",
    "# make multiprocessing pool; lets skip this for now\n",
    "\n",
    "p = mp.Pool(8)\n",
    "manager = mp.Manager()\n",
    "images_to_scores = manager.dict()\n",
    "images_to_scores = {}\n",
    "\n",
    "\n",
    "# p.map(real_predict_star, itertools.izip(images_for_tagging[:10], itertools.repeat(args)))\n",
    "# p.close()\n",
    "# p.join()\n",
    "\n",
    "a = mp.Process(target=predict, args=((images_for_tagging[7], args)))\n",
    "b = mp.Process(target=predict, args=((images_for_tagging[8], args)))\n",
    "a.start()\n",
    "b.start()\n",
    "a.join()\n",
    "b.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_to_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = [a.name for a in sess.graph.get_operations()]\n",
    "for layer in x:\n",
    "    print layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = sess.graph\n",
    "b = a.get_tensor_by_name(\"final_result:0\")\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
